####################初始规则######################################
#cmd params 中支持宏变量 ${CLUSTER_HOST_LIST} ${CLUSTER_IP_LIST} ${LOCAL_HOST} ${HOST_NAME_0} ${HOST_NAME_1} ${HOST_NAME_N} ${LOCAL_IP} ${HOST_IP_0} ${HOST_IP_1} ${HOST_IP_N}
## ${APP_HOST_LIST}  APP安装主机名称列表 对应app.zookeeper.install.hosts
# ${INSTALL_BASE}   ${LOGS_BASE} ${DATA_BASE}  ${APP_BASE} 
#
#依赖项请不要配置成循环依赖
#
#
ssh.config.use.shell=false
host.ssh.connect.timeout.ms=30000
host.install.jdk=true
host.yum.install.plugins=
app.start.sleep.interval.ms=1000
ssh.install.temp.dir=/tmp

app.install.host.list=
host.hostname.userdefine.hosts=
host.app.install.parallel=true

#安装源根目录
app.src.path.base=/app/ins
#sftp://root:sobey.datatom@172.16.131.37/sobeyhive/installer-1.2/dev/installer-1.2/app_src

#安装根目录 ${INSTALL_BASE}  
app.install.path.base=/app
//应用目录base/app  ${APP_BASE}
app.install.path.app.dir=/app/app
//数据目录base/data ${DATA_BASE}
app.install.path.data.dir=/app/data
//日志目录base/logs  ${LOGS_BASE}
app.install.path.logs.dir=/app/logs
#不可修改，做提示用
#app.package.name.rule={appName}/{appName}_{version}.tar.gz

#下面的值将写入临时变量，在本配置文件中可通过${key}方式获取
app.install.env={"NEBULA_VIP":"172.16.131.40","PRODUCT_DOMAIN":"pf.hive.sobey.com","DOCKER_NETWORK_NAME":"hivenet"\
,"DOCKER_NETWORK_HOSTS":"--add-host=${HOST_NAME_0}:${HOST_IP_0} --add-host=${HOST_NAME_1}:${HOST_IP_1} --add-host=${HOST_NAME_2}:${HOST_IP_2} "\
,"INSTALL_LVS":"false","INSTALL_DNS":"true","INSTALL_FIREWALLD":"false"  \
}


#参数为需要导出的环境变量,单个值中不要有回车
host.install.init.shell=${APP_BASE}/install/host_init.sh  ${LOCAL_IP} ${LOCAL_HOST}  
host.install.env.shell=${INSTALL_HOME}/bin/install/appenv.sh
host.install.lvs=false
#
cluster.install.start.shell=${APP_BASE}/install/cluster_init.sh 
cluster.install.end.shell=${APP_BASE}/install/cluster_end.sh
cluster.expand.start.shell=${APP_BASE}/install/cluster_expand_init.sh 
cluster.expand.end.shell=${APP_BASE}/install/cluster_expand_end.sh 
cluster.upgrade.start.shell=${APP_BASE}/install/cluster_upgrade_init.sh 
cluster.upgrade.end.shell=${APP_BASE}/install/cluster_upgrade_end.sh 
cluster.host.reinstall.shell=${APP_BASE}/install/cluster_host_reinstall_init.sh 

app.roles=zookeeper,haproxy,keepalived,docker,registry,installer,paasman,mysql,mycat,mongo,redis,kafka,eagles,elasticsearch
cluster.roles=docker,registry,redis,mysql,mongo,kafka
expand.roles=docker,registry,paasman,haproxy,keepalived,zookeeper,mysql,kafka,eagles
upgrad.roles=

app.install.default.user=root
cluster.user.start.userid=20000
#app.install.host.users={\
#"docker":"docker"\
#,"zookeeper":"zookeeper"\
#,"web":"web"\
#,"data":"data"\
#,"mongo":"mongo"\
#}

#app.zookeeper.install.user=zookeeper
#app.logstash.install.user=docker
#app.docker.install.user=docker
#app.mongo.install.user=mongo
#app.codis.install.user=docker
#app.kafka.install.user=docker
#app.hivecore.install.user=data
#app.ftengine2.install.user=data
#app.nebula.install.user=nebula
##cluster.registry.install.user=docker
  

##############################zookeeper
app.zookeeper.appName=zookeeper
app.zookeeper.versions=3.4.6
app.zookeeper.isSwarmService=false
app.zookeeper.appBusGroup=HP
app.zookeeper.configPortKey=clientPort
app.zookeeper.defaultPort=2181
app.zookeeper.dependRoles=docker
app.zookeeper.desc="分布式框架"
#app.zookeeper.install.hosts=0,1,2
#以\n拆分多个环境变量
app.zookeeper.export.rule=
app.zookeeper.install.rule=
app.zookeeper.init.rule=
app.zookeeper.install.rule=${APP_BASE}/install/zookeeper/zookeeper_install.sh zookeeper ${LOCAL_HOST} ${APP_VERSION} 
app.zookeeper.start.rule=${APP_HOME}/sbin/start_zookeeper.sh
app.zookeeper.config.rule= 
app.zookeeper.check.rule=
app.zookeeper.stop.rule= ${APP_HOME}/bin/zkServer.sh stop
app.zookeeper.unclean=false
app.zookeeper.unclean.config=${APP_HOME}/conf/zoo.cfg
app.zookeeper.config={"${APP_HOME}/conf/zoo.cfg":"tickTime=2000\
initLimit=10\
syncLimit=5\
dataDir=${DATA_BASE}/zookeeper\
clientPort=2181\
maxClientCnxns=3000\
maxSessionTimeout=1800000\
autopurge.snapRetainCount=3  \
autopurge.purgeInterval=1 \
server.1=${HOST_NAME_0}:2888:3888\
server.2=${HOST_NAME_1}:2888:3888\
server.3=${HOST_NAME_2}:2888:3888\
dataLogDir=${LOGS_BASE}/zookeeper\
"}
app.zookeeper.comtype=0

##############################docker
app.docker.install.hosts=0,1,2
app.docker.versions=17.09.1
app.docker.appBusGroup=HP
app.docker.export.rule=
app.docker.dependRoles=
app.docker.desc="容器服务"
app.docker.noneroot.sudoflag=true
app.docker.init.rule=
app.docker.install.rule=${APP_HOME}/docker_install.sh ${APP_HOME}/docker.cfg  ${APP_VERSION} 
app.docker.start.rule=${APP_HOME}/sbin/start_docker.sh
app.docker.config.rule=docker pull centos
app.docker.check.rule=
app.docker.stop.rule=${APP_HOME}/sbin/stop_docker.sh
app.docker.comtype=1
app.docker.unclean=false
app.docker.unclean.config=
app.docker.config={"${APP_HOME}/docker.cfg":"\
#是否自启动服务 \
DOCKER_SERVICE_ENABLE=true\
# /etc/sysconfig/docker --bip=192.168.100.1/24 \
DOCKER_OPTIONS=-H unix:///var/run/docker.sock --bip=10.88.0.1/24 --exec-opt native.cgroupdriver=cgroupfs --graph=${DATA_BASE}/docker --storage-driver devicemapper --log-opt max-size=10m --log-opt max-file=2 --storage-opt dm.fs=xfs --storage-opt dm.basesize=2G --storage-opt dm.override_udev_sync_check=true \
# /etc/sysconfig/docker-network  --cluster-store=zk://192.168.31.208:2181 --cluster-advertise=${IPINTERFACE}:2376  \
# /etc/sysconfig/docker \
DOCKER_NETWORK_OPTIONS=\
#--cluster-advertise=eth0:2376 \
#DOCKER_NETWORK_NAMES=sobeyficus\
#网络特定参数 \
#DOCKER_NETWORK_NAME.sobeyficus.params=--subnet 11.11.0.0/16 \
DOCKER_GROUP_USER=root\
"}

##############################registry
app.registry.install.hosts=
app.registry.appBusGroup=HP
app.registry.versions=2.6.0
app.registry.dependRoles=docker
app.registry.init.rule= chmod -R 777 ${APP_HOME}
app.registry.install.rule=echo hello world
app.registry.start.rule=echo hello world
app.registry.check.rule=
app.registry.stop.rule=echo hello world
app.registry.unclean=false
app.registry.unclean.config=
app.registry.config= 
app.registry.comtype=0

##############################installer
app.installer.install.hosts=0,1,2
app.installer.versions=1.3.0
app.installer.appBusGroup=HP
app.installer.export.rule=
app.installer.dependRoles=zookeeper,docker
app.installer.desc="安装框架"
app.installer.init.rule=
app.installer.install.rule=${APP_BASE}/install/installer/install_deploy.sh ${LOCAL_IP} ${LOCAL_HOST} ${APP_VERSION} 
app.installer.start.rule=${APP_HOME}/sbin/start_deploy.sh
app.installer.config.rule=
app.installer.check.rule=
app.installer.stop.rule=${APP_HOME}/sbin/stop_deploy.sh
app.installer.comtype=0
app.installer.unclean=false
app.installer.config={"${APP_HOME}/conf/installer.cfg":"\
ui.port=64001\
proxy.port=2222\
use_lbservice_for_haproxy=false\
"}

##############################paasman
app.paasman.install.hosts=
app.paasman.versions=1.0.0
app.paasman.appBusGroup=HP
#app.paasman.install.user=root
app.paasman.dependRoles=docker,installer
app.paasman.desc="服务管理"
app.paasman.isSwarmService=false
app.paasman.init.rule=
app.paasman.install.rule=${APP_HOME}/start_install_paasman.sh ${LOCAL_IP} ${APP_VERSION} 
app.paasman.start.rule=${APP_HOME}/sbin/start_paasman.sh
app.paasman.check.rule=
app.paasman.stop.rule=${APP_HOME}/sbin/stop_paasman.sh
app.paasman.unclean=false
app.paasman.unclean.config=
app.paasman.config={"${APP_HOME}/paasman_install.cfg":"\
isSwarmService=${app_paasman_isSwarmService} \
webport=64000"}
app.paasman.comtype=0

##############################keepalived
app.keepalived.install.hosts=
app.keepalived.versions=1.2.13
app.keepalived.appBusGroup=HP
app.keepalived.dependRoles=haproxy
app.keepalived.desc="高可用组件"
app.keepalived.init.rule= chmod -R 777 ${APP_HOME}
app.keepalived.install.rule=${APP_HOME}/install_keepalived.sh ${LOCAL_IP} ${LOCAL_HOST} ${APP_VERSION} 
app.keepalived.start.rule=service keepalived start
app.keepalived.check.rule=
app.keepalived.stop.rule=service keepalived stop
app.keepalived.unclean=false
app.keepalived.unclean.config=
app.keepalived.config={"${APP_HOME}/keepalived_install.conf":"CLUSTER_VIP=${NEBULA_VIP} \
VIP_ID=20 \
VIP_NAME=VI_20 \
SERVICE_ENABLE=true\
host.install.lvs=false\
"} 
app.keepalived.comtype=0

##############################haproxy
app.haproxy.install.hosts=
app.haproxy.versions=1.7.8
app.haproxy.appBusGroup=HP
#依赖程序，依赖的程序需要在app.roles中存在
app.haproxy.dependRoles=docker
app.haproxy.desc="负载均衡组件"
#app.haproxy.home=${APP_BASE}/{appName}/{appName}-{version}
app.haproxy.init.rule=
app.haproxy.install.rule=${APP_HOME}/install_haproxy.sh ${LOCAL_IP} ${CLUSTER_HOST_LIST}  ${APP_VERSION} 
app.haproxy.start.rule=service haproxy restart 
app.haproxy.check.rule=
app.haproxy.stop.rule=service haproxy stop 
app.haproxy.unclean=false
app.haproxy.unclean.config=
app.haproxy.config={"${APP_HOME}/conf/haproxy_install.conf":"\
#https:http
HTTPS_PORTS_MAP=85:88 84:86 9125:9021 9123:9023 9145:9045 10500:10555 9127:9027 9131:9031 9133:9033 9137:9037 9147:9047 9149:9049 9153:9053 9135:9035 9192:9092 9188:9088 9701:9601 9157:9057 9703:9603\
HTTPS_PORTS_MAP=85:88 84:86 \
useLbService=false \
"}
app.haproxy.comtype=0
 
##############################redis
app.redis.install.hosts=
app.redis.versions=3.2.8
app.redis.appBusGroup=HP
app.redis.dependRoles=docker
app.redis.desc="内存数据库"
app.redis.install.rule=${APP_HOME}/start_install_redis.sh ${LOCAL_IP} ${LOCAL_HOST} ${APP_VERSION} 
app.redis.start.rule=${APP_HOME}/sbin/start_redis.sh
app.redis.check.rule=
app.redis.stop.rule=${APP_HOME}/sbin/stop_redis.sh
app.redis.unclean=false
app.redis.unclean.config=
app.redis.config={"${APP_HOME}/redis_install.conf":"redis.port=6389\
storage.rootpath=/infinityfs1/hivefiles/sobeyhive"} 
app.redis.comtype=0

##############################kafka
app.kafka.appName=kafka
app.kafka.appBusGroup=HP
app.kafka.versions=2.11.0
app.kafka.dependRoles=docker,zookeeper
app.kafka.desc="分布式消息队列"
app.kafka.unclean=true
app.kafka.unclean.config=${APP_HOME}/kafka_install.conf
app.kafka.init.rule=${APP_BASE}/install/user_perm_init.sh root /etc/logrotate.d 2
app.kafka.install.rule=${APP_HOME}/start_install_kafka.sh ${LOCAL_IP} ${LOCAL_HOST} ${APP_VERSION} 
app.kafka.start.rule=${APP_HOME}/sbin/start_kafka_cluster.sh
app.kafka.stop.rule=${APP_HOME}/sbin/stop_kafka_cluster.sh
app.kafka.config={"${APP_HOME}/kafka_install.conf":" \
kafka.appdir=${APP_HOME} \
kafka.docker.imagefile=kafka-2.11.0.tar \
kafka.port=8092 \
kafka.data.dir=${DATA_BASE}/kafka \
kafka.log.dir=${LOGS_BASE}/kafka \
kafka.config.dir=${APP_HOME}/config \
kafka.config.file=${APP_HOME}/config/server.properties \
"}
app.kafka.comtype=0

##############################mysql
app.mysql.install.hosts=
app.mysql.versions=5.6.42
app.mysql.appBusGroup=HP
app.mysql.dependRoles=docker
app.mysql.desc="关系型数据库"
app.mysql.init.rule=
app.mysql.install.rule=${APP_HOME}/start_install_mysql.sh ${LOCAL_IP} ${LOCAL_HOST} ${APP_VERSION} 
app.mysql.start.rule=
app.mysql.check.rule=
app.mysql.stop.rule=
app.mysql.unclean=false
app.mysql.unclean.config=
app.mysql.config={"${APP_HOME}/conf/mysql-install.conf":"defaultPort=3306\
galeraPort=4567\
galeraISTPort=4568\
galeraSSTPort=4444"}
app.mysql.comtype=0

##############################mycat
app.mycat.versions=1.6.5
app.mycat.install.parallel=true
app.mycat.isSwarmService=false
app.mycat.swarmServiceMode=global
app.mycat.dependRoles=mysql
app.mycat.desc=""
app.mycat.appType=dockerService
app.mycat.appBusGroup=HP
app.mycat.comtype=0
app.mycat.autoRestart=true
app.mycat.noneroot.sudoflag=false
app.mycat.checkStatusInterval=10000
app.mycat.restartWaitTime=0
app.mycat.desc=mycat
app.mycat.init.rule=${APP_HOME}/sbin/init_mycat_config.sh ${LOCAL_IP} ${LOCAL_HOST} ${APP_VERSION} 
app.mycat.install.rule=${APP_HOME}/start_install_mycat.sh ${LOCAL_IP} ${LOCAL_HOST} ${APP_VERSION} 
app.mycat.start.rule=${APP_HOME}/sbin/start_mycat.sh
app.mycat.config.rule=${APP_HOME}/sbin/config_mycat_with_hivedb.sh ${LOCAL_HOST} 3306 sdba sdba true one 
app.mycat.check.rule=
app.mycat.stop.rule=${APP_HOME}/sbin/stop_mycat.sh
app.mycat.defaultPort=8066
app.mycat.portConfigKey=
app.mycat.config={"${APP_HOME}/conf/mycat_install.conf":"\
PORT_8066=8066\
PORT_9066=9066\
VOLUME_0=${APP_HOME}/conf/\
VOLUME_1=${LOGS_BASE}/mycat\
","${APP_HOME}/conf/myid.properties":"loadZk=true\
zkURL=${ZOOKEEPER_URL}\
clusterId=hivemysql\
myid=${LOCAL_HOST}\
clusterSize=1\
clusterNodes=${CLUSTER_HOST_LIST}\
type=server\
"}

##############################mongo
app.mongo.install.hosts=
app.mongo.appBusGroup=HP
app.mongo.versions=3.4.6
#依赖程序，依赖的程序需要在app.roles中存在
app.mongo.dependRoles=docker
app.mongo.desc="文档型数据库"
app.mongo.init.rule=chmod -R 777 ${APP_HOME}
app.mongo.install.rule=${APP_HOME}/start_Install_mongodb.sh ${LOCAL_IP} ${LOCAL_HOST} ${APP_VERSION} 
app.mongo.start.rule=
app.mongo.check.rule=
app.mongo.stop.rule=
app.mongo.unclean=false
app.mongo.unclean.config=
app.mongo.config={"${APP_HOME}/mongo_cluster.conf":"mongo.docker.imagefile=mongo_image.tar \
mongos.logdir=${LOGS_BASE}/mongo/mongos \
configdb.port=27917 \
configdb.datadir=${DATA_BASE}/mongo/cfgdb \
configdb.logdir=${LOGS_BASE}/mongo/cfgdb \
configdb.iplist=${HOST_NAME_0}:27917,${HOST_NAME_1}:27917,${HOST_NAME_2}:27917 \
shardreplicaset.count=1 \
shardreplicaset.port=27NUM17 \
shardreplicaset.datadir=${DATA_BASE}/mongo/hiveshard-NUM \
shardreplicaset.logdir=${LOGS_BASE}/mongo/hiveshard-NUM \
#下面用于描述shard的分片IP表，以分号分组，每组的第一个IP是主IP，shell脚本将在这个节点上执行 \
shardreplicaset.ipmap=${HOST_NAME_2},${HOST_NAME_0},${HOST_NAME_1} \
#控制是否启用mongo密码 \
isMongoPasswd=true \
mongoUser=sobeyhive \
mongoPasswd=$0bEyHive*2o1Six \
"}
app.mongo.comtype=0

##############################eagles
app.eagles.appName=eagles
app.eagles.appBusGroup=HP
app.eagles.install.hosts=0,1,2
app.eagles.dependRoles=docker
app.eagles.desc="日志引擎"
app.eagles.versions=3.1.3
app.eagles.init.rule=
app.eagles.install.rule=${APP_HOME}/start_install_eagles.sh ${LOCAL_IP} ${LOCAL_HOST} ${APP_VERSION}
app.eagles.config={"${APP_HOME}/eagles_install.conf":"\
eagles.datadir=${DATA_BASE}/eagles \
eagles.logdir=${LOGS_BASE}/eagles \
"}
app.eagles.comtype=0
 

##############################elasticsearch
app.elasticsearch.appName=elasticsearch
app.elasticsearch.appBusGroup=HP
app.elasticsearch.install.hosts=0,1,2
app.elasticsearch.dependRoles=docker
app.elasticsearch.desc=""
app.elasticsearch.versions=2.4.5
app.elasticsearch.init.rule=
app.elasticsearch.install.rule=${APP_HOME}/start_install_elasticsearch.sh ${LOCAL_IP} ${LOCAL_HOST} ${APP_VERSION}
app.elasticsearch.start.rule=${APP_HOME}/sbin/start_elasticsearch.sh
app.elasticsearch.stop.rule=${APP_HOME}/sbin/stop_elasticsearch.sh
app.elasticsearch.config={"${APP_HOME}/elasticsearch_install.conf":"\
elasticsearch.datadir=${DATA_BASE}/elasticsearch \
elasticsearch.logdir=${LOGS_BASE}/elasticsearch \
"}
app.elasticsearch.comtype=0
                                

##############################集群配置##############################

##############################docker
cluster.docker.install.hosts=0,1,2
cluster.docker.dependRoles=
cluster.docker.install.rule=${APP_BASE}/install/swarm_manager.sh init ${CLUSTER_HOST_LIST}
cluster.docker.start.rule=
cluster.docker.config.rule=${APP_HOME}/docker_config.sh ${APP_HOME}/docker.cfg
cluster.docker.check.rule=
cluster.docker.stop.rule=
cluster.docker.unclean=false
cluster.docker.unclean.config=
cluster.docker.config={}

##############################registry
cluster.registry.install.hosts=0,1,2
cluster.registry.appBusGroup=HP
cluster.registry.defaultPort=5000
cluster.registry.isSwarmService=false
cluster.registry.dependRoles=docker
cluster.registry.versions=2.6.0
cluster.registry.init.rule=${APP_BASE}/install/user_perm_init.sh ${APP_USER} /infinityfs1/docker  1
cluster.registry.install.rule=${APP_HOME}/install_registry.sh /infinityfs1/docker/registry sobey hive ${CLUSTER_HOST_LIST} 
cluster.registry.start.rule=
cluster.registry.config.rule=
cluster.registry.check.rule=
cluster.registry.stop.rule=
cluster.registry.unclean=false
cluster.registry.unclean.config=
cluster.registry.config={"${APP_HOME}/conf/registry_install.conf":"USE_HTTPS=true\
USE_AUTHENTICATION=true\
isSwarmService=${cluster_registry_isSwarmService} \
"}
cluster.registry.comtype=0

##############################mysql
cluster.mysql.install.hosts=0,1,2
#下面的check命令很重要，用于判断集群是否构建成功，一旦成功则修改回正常集群启动的配置
cluster.mysql.install.rule=
cluster.mysql.start.rule=${APP_HOME}/sbin/start_mysql_cluster.sh
cluster.mysql.check.rule=${APP_HOME}/sbin/check_mysql_cluster.sh
cluster.mysql.config.rule=
cluster.mysql.stop.rule=${APP_HOME}/sbin/stop_mysql_cluster.sh
cluster.mysql.unclean=false
cluster.mysql.unclean.config=
cluster.mysql.config={}

##############################mongo
cluster.mongo.install.hosts=0,1,2
cluster.mongo.appName=mongo
cluster.mongo.install.rule=cd ${APP_HOME}
cluster.mongo.start.rule=${APP_HOME}/sbin/start_mongo_cluster.sh
cluster.mongo.config.rule=${APP_HOME}/mongo_cluster_config.sh
cluster.mongo.check.rule=${APP_HOME}/sbin/check_mongo_cluster_status.sh
cluster.mongo.stop.rule=${APP_HOME}/sbin/stop_mongo_cluster.sh
cluster.mongo.unclean=false
cluster.mongo.unclean.config=
cluster.mongo.config={}
 

##############################redis
cluster.redis.install.hosts=0,1,2
cluster.redis.appName=redis
cluster.redis.install.rule=${APP_HOME}/redis_cluster_config.sh 
cluster.redis.start.rule=${APP_HOME}/sbin/start_redis_cluster.sh
cluster.redis.check.rule=
cluster.redis.config.rule=
cluster.redis.stop.rule=${APP_HOME}/sbin/stop_redis_cluster.sh
cluster.redis.config={}

##############################kafka
cluster.kafka.install.hosts=0,1,2
cluster.kafka.start.rule=${APP_HOME}/sbin/start_kafka_cluster.sh
cluster.kafka.config.rule=${APP_HOME}/kafka_cluster_config.sh
cluster.kafka.check.rule=${APP_HOME}/sbin/check_kafka_cluster_status.sh
cluster.kafka.stop.rule=${APP_HOME}/sbin/stop_kafka_cluster.sh
           
##############################扩容配置##############################
##############################zookeeper
#expand.zookeeper.expand.hosts=
expand.zookeeper.oldhost.rule=${APP_BASE}/install/zookeeper/zookeeper_expand.sh 
#重新配置先前的主机
expand.haproxy.oldhost.rule=${APP_BASE}/install/haproxy/haproxy_expand.sh 
 

##############################docker##############################
expand.docker.init.rule=
expand.docker.install.rule=
expand.docker.start.rule=
expand.docker.config.rule=${APP_BASE}/install/docker/docker_expand.sh
expand.docker.check.rule=
expand.docker.oldhost.rule=
expand.docker.config={}

############################升级配置##################################

#升级命令脚本, 自动传入参数 所有主机和扩容主机列表


